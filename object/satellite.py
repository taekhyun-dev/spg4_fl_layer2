# object/satellite.py
import asyncio
import torch
import torch.nn as nn
import torch.optim.lr_scheduler as lr_scheduler

from typing import List, Dict, Tuple, Coroutine
from datetime import datetime
from typing import Tuple, Dict
from ml.model import PyTorchModel, create_mobilenet
from ml.training import evaluate_model, fed_avg
from utils.skyfield_utils import EarthSatellite
from utils.logging_setup import KST
from utils.config import LOCAL_EPOCHS, FEDPROX_MU, MAX_ISL_DISTANCE_KM
from object.clock import SimulationClock

# ----- CLASS DEFINITION ----- #
class Satellite:
    def __init__ (self, sat_id: int, satellite_obj: EarthSatellite, clock: 'SimulationClock', sim_logger, perf_logger,
                   initial_model: PyTorchModel):
        self.sat_id = sat_id
        self.satellite_obj = satellite_obj
        self.clock = clock
        self.logger = sim_logger
        self.perf_logger = perf_logger
        self.position = {"lat": 0.0, "lon": 0.0, "alt": 0.0}
        self.state = "IDLE"
        self.global_model = initial_model
        self.model_ready_to_upload = False
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

class WorkerSatellite(Satellite):
    def __init__ (self,
                    sat_id: int, 
                    satellite_obj: EarthSatellite, 
                    clock: 'SimulationClock', 
                    sim_logger, 
                    perf_logger, 
                    initial_model: PyTorchModel,
                    master: 'MasterSatellite', train_loader, val_loader):
        super().__init__(sat_id, satellite_obj, clock, sim_logger, perf_logger, initial_model)
        self.master = master
        self.local_model = self.global_model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.logger.info(f"Worker SAT {self.sat_id} ìƒì„±")

    def _train_and_eval(self) -> Tuple[Dict, float, float]:
        """
        ì‹¤ì œ PyTorch ëª¨ë¸ í•™ìŠµì„ ìˆ˜í–‰í•˜ëŠ” ë¸”ë¡œí‚¹(ë™ê¸°) í•¨ìˆ˜.
        asyncio ì´ë²¤íŠ¸ ë£¨í”„ë¥¼ ë§‰ì§€ ì•Šê¸° ìœ„í•´ ë³„ë„ì˜ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.
        """
        try:
            loader_length = len(self.train_loader)
            self.logger.info(f"âœ… DataLoaderì˜ ì´ ë°°ì¹˜ ê°œìˆ˜: {loader_length}")
            if loader_length == 0:
                self.logger.error("âš ï¸ DataLoaderê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. Datasetì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return # ë˜ëŠ” ë‹¤ë¥¸ ì—ëŸ¬ ì²˜ë¦¬
        except Exception as e:
            self.logger.error(f"âŒ DataLoaderì˜ ê¸¸ì´ë¥¼ í™•ì¸í•˜ëŠ” ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")

        # --- í•™ìŠµ íŒŒíŠ¸ ---
        temp_model = create_mobilenet()
        temp_model.load_state_dict(self.local_model.model_state_dict)
        temp_model.to(self.device)
        temp_model.train()

        # --- FedProx ì¶”ê°€ ë¶€ë¶„ ---
        #    global_model_ref (w^t): Proximal term ê³„ì‚°ì„ ìœ„í•œ 'ê³ ì •ëœ' ê¸°ì¤€ ëª¨ë¸
        #    ë§ˆì°¬ê°€ì§€ë¡œ 'self.global_model' (w^t)ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§€ë©°, í•™ìŠµë˜ì§€ ì•Šë„ë¡ .eval()
        global_model_ref = create_mobilenet()
        global_model_ref.load_state_dict(self.global_model.model_state_dict)
        global_model_ref.to(self.device)
        global_model_ref.eval() # ì¤‘ìš”: gradientê°€ íë¥´ì§€ ì•Šë„ë¡ ì„¤ì •

        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(temp_model.parameters(), lr=3e-4, weight_decay=1e-4)
        scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)
    
        for epoch in range(LOCAL_EPOCHS):
            self.logger.info(f"    - SAT {self.sat_id}: ì—í¬í¬ {epoch+1}/{LOCAL_EPOCHS} ì§„í–‰ ì¤‘...")
            for images, labels in self.train_loader:
                images, labels = images.to(self.device), labels.to(self.device)
                optimizer.zero_grad()

                outputs = temp_model(images)
                loss = criterion(outputs, labels)
                
                # --- FedProx ì†ì‹¤ í•¨ìˆ˜ ìˆ˜ì • ë¶€ë¶„ ---
                #     ê·¼ì ‘ í•­(Proximal Term) ê³„ì‚°: ||w - w^t||^2
                prox_term = 0.0

                # temp_model.parameters() (w)ì™€ global_model_ref.parameters() (w^t) ë¹„êµ
                for local_param, global_param in zip(temp_model.parameters(), global_model_ref.parameters()):
                    # .detach()ë¥¼ ì‚¬ìš©í•˜ì—¬ w^tì˜ gradientê°€ ê³„ì‚°ë˜ì§€ ì•Šë„ë¡ í•¨
                    prox_term += torch.sum(torch.pow(local_param - global_param.detach(), 2))

                # --- FedProx ì†ì‹¤ í•¨ìˆ˜ ìµœì¢… ê³„ì‚° ë¶€ë¶„ ---
                #     ìµœì¢… ì†ì‹¤ ê³„ì‚°: Loss + (mu/2) * prox_term
                total_loss = loss + (FEDPROX_MU / 2) * prox_term

                # loss.backward()
                total_loss.backward()
                optimizer.step()
            scheduler.step()
            
        new_state_dict = temp_model.cpu().state_dict()
        self.logger.info(f"  ğŸ§  SAT {self.sat_id}: ë¡œì»¬ í•™ìŠµ ì™„ë£Œ ({LOCAL_EPOCHS} ì—í¬í¬). ê²€ì¦ ì‹œì‘...")
            
        # --- ê²€ì¦ íŒŒíŠ¸ ---
        accuracy, loss, miou = evaluate_model(new_state_dict, self.val_loader, self.device)
            
        return new_state_dict, accuracy, loss, miou

    async def train_and_eval(self):
        """CIFAR10 ë°ì´í„°ì…‹ìœ¼ë¡œ ë¡œì»¬ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ê²€ì¦"""
        self.state = 'TRAINING'
        self.logger.info(f"  âœ… SAT {self.sat_id}: ë¡œì»¬ í•™ìŠµ ì‹œì‘ (v{self.local_model.version}).")
        new_state_dict = None
        try:
            # í˜„ì¬ ì‹¤í–‰ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            loop = asyncio.get_running_loop()
            new_state_dict, accuracy, loss, miou = await loop.run_in_executor(None, self._train_and_eval)
            self.local_model.model_state_dict = new_state_dict
            self.logger.info(f"  ğŸ“Š [Local Validation] SAT: {self.sat_id}, Version: {self.local_model.version}, Accuracy: {accuracy:.2f}%, Loss: {loss:.4f}, Miou: {miou:.2f}%")
            self.perf_logger.info(f"{datetime.now(KST).isoformat()},LOCAL_VALIDATION,{self.sat_id},{self.local_model.version},N/A,{accuracy:.4f},{loss:.6f},{miou:.4f}")

            self.local_model.trained_by = [self.sat_id]
            self.model_ready_to_upload = True

        except Exception as e:
            self.logger.error(f"  ğŸ’€ SAT {self.sat_id}: í•™ìŠµ ë˜ëŠ” ê²€ì¦ ì¤‘ ì—ëŸ¬ ë°œìƒ - {e}", exc_info=True)

        finally:
            self.state = 'IDLE'
            self.logger.info(f"  ğŸ SAT {self.sat_id}: í•™ìŠµ ì ˆì°¨ ì™„ë£Œ.")

    async def send_model_to_iot(self, iot: 'IoT'):
        if self.global_model.version > iot.global_model.version:
            self.logger.info(f"  ğŸ›°ï¸ SAT {self.sat_id} -> IoT {iot.name}: ê¸€ë¡œë²Œ ëª¨ë¸ ì „ì†¡ (ë²„ì „ {self.global_model.version})")
            await iot.receive_global_model(self.global_model)

    async def send_local_model(self) -> PyTorchModel | None:
        if self.model_ready_to_upload:
            self.model_ready_to_upload = False
            return self.local_model
        return None

class MasterSatellite(Satellite):
    def __init__(self,
                 sat_id: int, 
                 satellite_obj: EarthSatellite, 
                 clock: 'SimulationClock', 
                 sim_logger, 
                 perf_logger, 
                 initial_model: PyTorchModel,
                 test_loader):
        super().__init__(sat_id, satellite_obj, clock, sim_logger, perf_logger, initial_model)
        self.test_loader = test_loader
        self.cluster_model = self.global_model
        self.cluster_version_counter = 0
        
        self.cluster_members: Dict[int, WorkerSatellite] = {}
        self.cluster_model_buffer: List[PyTorchModel] = []
        self.logger.info(f"Master SAT {self.sat_id} ìƒì„±")

    def add_member(self, worker: WorkerSatellite):
        self.cluster_members[worker.sat_id] = worker

    async def receive_global_model(self, model: PyTorchModel):
        """ì§€ìƒêµ­ìœ¼ë¡œë¶€í„° ê¸€ë¡œë²Œ ëª¨ë¸ì„ ìˆ˜ì‹ """
        self.logger.info(f"  ğŸ›°ï¸ Master SAT {self.sat_id}: ìƒˆë¡œìš´ ê¸€ë¡œë²Œ ëª¨ë¸ ìˆ˜ì‹  (v{model.version}).")
        self.global_model = model
        self.cluster_model = model
        self.model_ready_to_upload = False

    async def send_model_to_worker(self, worker: WorkerSatellite):
        self.logger.info(f"  ğŸ›°ï¸ -> ğŸ›°ï¸  Master {self.sat_id} -> Worker {worker.sat_id}: ëª¨ë¸ ì „ì†¡ (ë²„ì „ {self.cluster_model.version})")
        worker.local_model = self.cluster_model
        # ëª¨ë¸ì„ ë°›ì€ ì›Œì»¤ëŠ” ë‹¤ì‹œ í•™ìŠµí•  ì¤€ë¹„ê°€ ëœ ê²ƒì´ë¯€ë¡œ IDLE ìƒíƒœë¡œ ë³€ê²½
        if worker.state == 'WAITING_TRAINING':
            worker.state = 'IDLE'

    async def receive_model_from_worker(self, worker: WorkerSatellite):
        self.cluster_model_buffer.append(worker.local_model)
        worker.model_ready_to_upload = False
        self.logger.info(f"  ğŸ“¥ MasterSAT {self.sat_id}: Worker {worker.sat_id} ëª¨ë¸ ìˆ˜ì‹ . (ë²„í¼ í¬ê¸°: {len(self.cluster_model_buffer)})")

    async def aggregate_models_periodically(self):
        """ì£¼ê¸°ì ìœ¼ë¡œ ë²„í¼ì— ìŒ“ì¸ ì›Œì»¤ ëª¨ë¸ë“¤ì„ ì·¨í•©"""
        while True:
            # await asyncio.sleep(30)
            await asyncio.sleep(2)
            if not self.cluster_model_buffer:
                continue
            await self._aggregate_and_evaluate_cluster_models()

    async def _aggregate_and_evaluate_cluster_models(self):
        """ì‹¤ì œ ëª¨ë¸ ì·¨í•© ë° í‰ê°€ ë¡œì§"""
        self.logger.info(f"  âœ¨ [Cluster Aggregation] Master {self.sat_id}: {len(self.cluster_model_buffer)}ê°œ ì›Œì»¤ ëª¨ë¸ê³¼ ê¸°ì¡´ í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì·¨í•© ì‹œì‘")
        
        state_dicts_to_avg = [self.cluster_model.model_state_dict] + [m.model_state_dict for m in self.cluster_model_buffer]
        new_state_dict = fed_avg(state_dicts_to_avg)
        all_contributors = list(set(self.cluster_model.trained_by + [p for model in self.cluster_model_buffer for p in model.trained_by]))
        
        self.cluster_model.model_state_dict = new_state_dict
        self.cluster_model.trained_by = all_contributors
        self.model_ready_to_upload = True
        self.cluster_version_counter += 1
        self.logger.info(f"  âœ¨ [Cluster Aggregation] Master {self.sat_id}: í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ. í•™ìŠµì: {self.cluster_model.trained_by}")

        # í‰ê°€ë„ ë¸”ë¡œí‚¹ ì‘ì—…ì´ë¯€ë¡œ executorì—ì„œ ì‹¤í–‰
        accuracy, loss = await asyncio.get_running_loop().run_in_executor(
            None, evaluate_model, new_state_dict, self.test_loader, self.device
        )
        self.logger.info(f"  ğŸ§ª [Cluster Test] Owner: SAT_{self.sat_id}, Global Ver: {self.cluster_model.version}, Cluster Ver: {self.cluster_version_counter}, Accuracy: {accuracy:.2f}%, Loss: {loss:.4f}")
        self.perf_logger.info(f"{datetime.now(KST).isoformat()},CLUSTER_TEST,SAT_{self.sat_id},{self.cluster_model.version},{self.cluster_version_counter},{accuracy:.4f},{loss:.6f}")

        self.cluster_model_buffer.clear()

    async def send_cluster_model(self) -> PyTorchModel | None:
        if self.model_ready_to_upload:
            self.model_ready_to_upload = False
            return self.cluster_model
        return None

class Satellite_Manager:
    def __init__ (self, master: 'MasterSatellite', clock: 'SimulationClock', sim_logger):
        self.master = master
        self.logger = sim_logger
        self.clock = clock
        self.logger.info(f"Master SAT {self.master.sat_id} ìœ„ì„± ê´€ë¦¬ì ìƒì„± ì™„ë£Œ.")

    async def run(self):
        self.logger.info(f"Master SAT {self.master.sat_id} ìœ„ì„± ê´€ë¦¬ì ìš´ì˜ ì‹œì‘.")
        self.logger.info(f"Master SAT {self.master.sat_id} ì„ë¬´ ì‹œì‘.")
        for sat in self.master.cluster_members.values():
            self.logger.info(f"  Worker SAT {sat.sat_id} ì„ë¬´ ì‹œì‘.")
        await self.propagate_orbit_with_isl()

    async def propagate_orbit_with_isl(self):
        """ISLì„ í†µí•´ ì›Œì»¤ ìœ„ì„±ë“¤ê³¼ í†µì‹ í•˜ê³  ëª¨ë¸ì„ êµí™˜"""
        while True:
            await asyncio.sleep(self.clock.real_interval)
            await self._aggregate_and_evaluate_cluster_models()
            tasks = []
            for worker in self.master.cluster_members.values():
                distance = self.get_distance_between(self.master, worker)
                if distance <= MAX_ISL_DISTANCE_KM:
                    if self.master.cluster_model.version > worker.local_model.version or \
                    (self.master.cluster_model.version == worker.local_model.version and self.master.cluster_model.model_state_dict is not worker.local_model.model_state_dict):
                        send_model_task = asyncio.create_task(self.master.send_model_to_worker(worker))
                        tasks.append(send_model_task)
                    if worker.model_ready_to_upload:
                        receive_model_task = asyncio.create_task(self.master.receive_model_from_worker(worker))
                        tasks.append(receive_model_task)
            await asyncio.gather(*tasks)

            for worker in self.master.cluster_members.values():
                current_ts = self.clock.get_time_ts()
                geocentric = worker.satellite_obj.at(current_ts)
                subpoint = geocentric.subpoint()
                worker.position["lat"], worker.position["lon"], worker.position["alt"] = subpoint.latitude.degrees, subpoint.longitude.degrees, subpoint.elevation.km

            current_ts = self.clock.get_time_ts()
            geocentric = self.master.satellite_obj.at(current_ts)
            subpoint = geocentric.subpoint()
            self.master.position["lat"], self.master.position["lon"], self.master.position["alt"] = subpoint.latitude.degrees, subpoint.longitude.degrees, subpoint.elevation.km

    def get_distance_between(self, one_sat: 'Satellite', other_sat: 'Satellite') -> float:
        """ë‹¤ë¥¸ ìœ„ì„±ê³¼ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°"""
        current_ts = self.clock.get_time_ts()
        return (one_sat.satellite_obj - other_sat.satellite_obj).at(current_ts).distance().km